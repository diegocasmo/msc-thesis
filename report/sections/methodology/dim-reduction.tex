\section{Dimensionality Reduction} \label{sect:meth:dim-reduction}
% What is dimensionality?
% What is the curse of dimensionality?
In machine learning and statistics, it is common to refer to the number of features that make up an observation as its dimensionality. As the number of features that describe such observation increases, it is likely that one will encounter the so called ``curse of dimensionality''. The curse of dimensionality is associated with the fact that as the dimensionality of data increases, the more it becomes sparse in the space that it is represented. As a result, the definitions of properties such as the distance between distinct observations or density become less significant. \newline

% What is dimensionality reduction?
Dimensionality reduction refers to the process of reducing the number of features that describe an observation. Dimensionality reduction can be performed by either using feature selection (selecting a subset of the original features) or feature extraction (deriving new features from the original features). Dimensionality reduction can help avoid the curse of dimensionality, eliminate unsuitable features, reduce noise, and reduce the amount of time and memory required by machine learning or statistical algorithms. \newline

\todo[inline]{TODO: Define projections}
\todo[inline]{TODO: Explain how projections are used to reduce dimensionality}