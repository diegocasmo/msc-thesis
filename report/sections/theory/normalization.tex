\section{Normalization} \label{sect:theory:norm}

% What is normalization?
Normalization refers to the process of accommodating the values of observations so that their unit of measurement does not affect their contribution when compared to one another. Normalization essentially drops the unit of measurement from the observations, and as a result, it allows to examine observations that come from distinct places in a notionally common scale.  \newline

% Why use normalization?
As pointed out in section \ref{sect:theory:ml-blink}, the pair of items $\vect{x}_i$ and $\vect{y}_i$ are assumed to have been acquired from distinct sources, which means these sources might have used different devices and/or software processing techniques to collect the data. As a result, normalization is required in order to use a common ``scale'' between these two observations to avoid one unit of measurement dominating the other due to differences in the data acquisition step. \newline

% How does the ML-Blink algorithm use normalization?
The \mlblink algorithm uses the L2--norm as defined in equation \ref{eq:l2-norm} to normalize the input vectors. The normalization is performed by dividing each component of a vector by the vector's L2--norm. The resulting vector has the characteristic that the sum of each of the vector's component squared sums up to 1.

\begin{equation} \label{eq:l2-norm}
    \lVert \vect{x} \rVert_{2} = \sqrt{x^2_1 + x^2_2 + ... + x^2_n}
\end{equation}